---
title: Building a Peptide Database to Perform Automated Forensic Analysis of Toxins using Mass Spectrometry
subtitle: |
  | Capstone Report, Masters of Science, Bioinformatics
  | Advisors: Dr. Eckart Bindewald, Dr. Daniel Sierra-Sosa, Dr. Miranda Darby
author:
  - Daniel Vogel, Hood College
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: 'Bioterrorism has created a need for the rapid analysis of samples which may contain toxins, viruses, or other deadly agents. Mass Spectrometry (MS) provides a tool for use in proteomics for accurate and comprehensive profiling of proteins. An automated software tool which can search for matches against a proteome database is useful for forensic analysis of samples and an effective countermeasure to Bioterrorist attacks. Here we create a database for this purpose using publicly available proteomes from the Uniprot.org database [@10.1093/nar/gkaa1100].'
output: 
  pdf_document:
    toc: true
    toc_depth: 2
documentclass: report
bibliography: capstone.bib
#nocite: '@*'
header-includes:
  \usepackage{setspace}\doublespacing
  \usepackage{geometry}
  \geometry{top=0.75in,left=1.0in,bottom=0.75in,right=1.0in}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
\newpage

\chapter{Introduction}
Bioterrorism is the use of microorganisms or toxins by terrorist or extremists’ groups to produce weapons which cause death and disease [@jansen2014biological]. The use of biological agents (Bioweapons) to cause harm or death is not a new concept; countries have been engaging in bioterrorism for hundreds of years. Infectious diseases were recognized for their potential impact on people and armies as early as 600 BC. The crude use of filth and cadavers, animal carcasses, and contagion had devastating effects and weakened the enemy. Polluting wells and other sources of water of the opposing army was a common strategy that continued to be used through the many European wars, during the American Civil War, and even into the 20th century [@riedel2004biological]. More recently, bioterrorism events have been noted, one is the attack using anthrax-laden letters mailed to media organizations and politicians [@pal2017overview]. The National Biodefense Analysis and Countermeasures Center (NBACC) was created as a result.  At NBACC, techniques are developed to combat this threat. During the past century, the progress made in biotechnology and biochemistry has simplified the development and production of such weapons [@riedel2004biological]. Bacterial and plant protein toxins are among the most powerful poisons known. Protein toxins are considered as potential agents used for bioterrorism and warfare [@duracova2018proteomic]. It is predicted that proliferation of Bioweapons will increase in the next decades. Multi-tiered biodefense strategies are essential in mounting a successful response to bioterrorism. Mass spectrometry (MS) can be utilized in all stages of such a response: from Bioweapon detectors to forensics for successful prosecution [@demirev2008mass]. 

MS is the most comprehensive approach for the quantification of proteins [@sinha2020beginner]. MS provides a valuable tool for law enforcement’s forensic sample analysis. The accuracy of MS can also distinguish between similar compounds and organisms such as the castor bean vs the toxin Ricin. Current methods, involving manual database searches, are slow, and depend on expert knowledge. Automated solutions produce effective results for non-experts and narrow the search field for experts to perform more in-depth analysis. We must refine software and methods, improving accuracy and efficiency to combat the Bioweapon threat. 

Here we focus on bottom-up proteomics where proteins are digested into smaller peptides, which are analyzed by MS. Mass spectrometers detect the presence and quantity of peptides using properties of mass and net-charge. As Mass spectrometers can only analyze gaseous ions, peptides are converted into peptide ions which are separated by their mass-to-charge ratio (m/z). 

Samples are prepared for MS by digesting the long polypeptide chains using protease enzymes such as Trypsin, Chymotrypsin or Pepsin. These break them into smaller peptides which can be measured by MS. Protease digestion acts to normalize and compartmentalize the biochemical heterogeneity of proteins within a sample as peptides and may create a less heterogeneous mixture when protein splice isoforms and post-translational modifications are considered [@zhang2013protein]. One consideration due to the sensitivity of the MS analysis is that contaminant proteins will appear from Trypsin and human interaction and must be removed from analysis using a “crap.fasta” file. This file is customized to contain the amino acid sequences for contaminants such as human skin or animal proteins from the digesting enzyme. 

Bioinformatics analysis of MS output involves comparing matching the spectral output data from a sample with the theoretical spectra predicted from known genome or amino acid sequences contained in databases [@pere2020hood]. An intermediate step is to determine the peptide sequences using PEAKS® de-novo sequencing software. NBACC uses the MARLOWE tool, developed at the Pacific Northwest National Lab (PNNL), to automate this database searching, producing a list of potential candidate compounds or organisms and likelihood scores for each candidate. MARLOWE is an R-Markdown application where the user adjusts a few input parameters to control sensitivity and set sample data input file names. It then performs analysis and generates documents to show the candidate scoring. In testing the MARLOWE search with a sample of the toxin, abrin, no matches were found as this compound was missing from the database. 

We will rebuild the MARLOWE analysis software database from UniProt, a publicly available data source. The new database will be generated via in-silico digestion of Amino Acid sequences found in UniProt, using Trypsin. This will result in more accurate and updated searches. The MARLOWE database can be updated, at no cost as more samples are added to UniProt. We will evaluate the success and propose a method to process lab samples digested with enzymes Chymotrypsin or Pepsin [@dau2020proteomics].


\chapter{Literature Review and Previous work}

MARLOWE compares these peptides to a MySQL database which has been constructed from the Japanese KEGG.jp protein database [@kanehisa2002kegg]. The construction of the database requires taking the long amino acid sequences from each organism and digesting in-silico using an R subroutine, into smaller peptide sequences that match the digested lab sample. MARLOWE then uses an algorithm which compares the MS/PEAKS® data with the database peptides and makes a list of candidate organisms that may be contained in the sample. It produces scores and a heat map showing the most likely hits (Figure 1)

![Heat Map Communis Ricinis Sample on KEGG ](kegg_heatmap.jpeg)


\chapter{Specific Aims} 
Aim 1 is to create a new R package which will extract required fields from publicly available UniProt data [@10.1093/nar/gkaa1100] in fasta format. A major weakness of the MARLOWE tool is that the database was built using protein data from kegg.jp, more than 2 years ago. The database cannot be updated without a paid subscription to the kegg.jp FTP site which costs $25,000 per year for a single site license. The kegg data extraction subroutines in MARLOWE rely on regular expression to parse human readable .ent files from kegg.jp. The .ent files are not standard so these subroutines are not useful for any other sources [@csordas2012pride]. The fasta format is a standard so the R data extraction package will be adaptable to UniProt or other protein databases where fasta output is available. Successful adoption of the UniProt data will make MARLOWE cheaper and more accessible for use as licensed access to the kegg.jp FTP site is no longer required. 

I created a new UniProt based peptide database by downloading data from Uniprot’s uniref50 in fasta format and parsed it via the parse_fasta package to extract the data fields that MARLOWE requires. Creating the MARLOWE database from complete uniref50 data is a computationally intense process taking weeks on a powerful workstation or server.  There are over 100,000 organisms.  By extracting this data into a separate file for each, I can develop a faster method to create the database using parallel processing on an NBACC High Performance Computing (HPC) cluster. I have ported the MARLOWE code and database from Windows to Linux to make this possible. 

 

Aim 2 is to improve the accuracy and performance of the MARLOWE tool by updating the database with new samples and creating an efficient process to update the database as needed. When NBACC scientists tried to perform an analysis of a sample containing the toxin "abrin", the program did not identify abrin because the database was out of date and did not contain entries for abrin. These were added to the KEGG.JP database in the year after MARLOWE was created. Abrin protein sequences are currently contained in both UniProt and KEGG.JP protein databases. These databases are updated constantly with protein sequences, often in response to a new toxin or virus of interest. Addition of the latest entries from UniProt will improve the accuracy of the MARLOWE pipeline, increasing the chance to identify the candidate toxin without manual searching. 

Aim 2. I will download subsets from UniProt by using queries which will contain the compounds in the test samples, milk, abrin, and castor bean. I will then compare the resulting MARLOWE/UniProt analysis to that done with the MARLOWE/KEGG to validate the sample was found and compare the scoring. This will lead to a process which can be used to update the database as needed, in the future. As more entries are added to UniProt or other protein databases are identified, this process can be repeated. After validation of the extraction and database creation, we can develop a repeatable procedure to download the entire UniProt database. Additionally, if I can obtain access to the current KEGG.JP FTP site, I will create an updated MARLOWE/KEGG database to validate that “abrin” can now be located using the original MARLOWE code. 

\chapter{Resources, Tools, and Research Methodology} 

I am in the process of installing MARLOWE on a home server running Ubuntu 20.04LTS which has been upgraded with a high speed NVME SSD to store the database. I have also installed it on a Windows workstation at NBACC. MARLOWE was designed to run with Microsoft Windows® but I have converted it to run on Linux. I will test it on Ubuntu 20.04LTS and CentOS 7, and Red Hat RHEL 8 Linux. 

I have loaded the MARLOWE code into a GitHub.com repo so I can fork from the current version and create new packages which can be tested on various linux platforms. The code is written with R version 4.2.1 using the RStudio Development Environment and a database from UniProt data will be created with MySQL version 8.0.31 for Ubuntu Linux and MariaDB 5.5 for CentOS 7 Linux.

I will validate the output of MARLOWE (current version MySQL 8.0 on Windows 10, R version 3.6.1 ) with a few samples, including the Abrin sample, Milk, and Castor bean. To perform the analysis of the two databases, MARLOWE will be run against each database with the same samples. I will compare the output with the actual contents of the sample and make a conclusion on performance or improvements needed. 

![Fasta Communis Ricinis Sample](castor.head.PNG)


\chapter{Results}

Describe the results of the proposed project work. 

\section{Discussion}

Putting the results in context 

\chapter{Summary and Future Work}

\section{Alternate digestion enzyme} 
Currently MARLOWE only supports Trypsin digest. We can construct another version of the database where the peptides have been digested with an alternate protease enzyme.
\section{Software Improvements}
GUI interface would be possible by creating an R-Shiny version where the scientist could select their input files using a GUI and then the pipeline would run automatically and produce and output report that could be viewed and downloaded.
Automated database updates via API would allow adding new organisms to the database by pulling from UniProt via API and inserting into the MARLOWE candidate databases.

 
  
  
# References {-}





